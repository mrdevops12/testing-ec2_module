# win-arc-metrics-services.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: arc-controller-metrics
  labels:
    app: arc-controller
spec:
  type: ClusterIP
  ports:
    - name: http-metrics
      port: 8080
      targetPort: 8080
  selector:
    app.kubernetes.io/name: gha-rs-controller
---
apiVersion: v1
kind: Service
metadata:
  name: arc-listener-metrics
  labels:
    app: arc-listener
spec:
  type: ClusterIP
  ports:
    - name: http-metrics
      port: 8080
      targetPort: 8080
  selector:
    app.kubernetes.io/component: runner-scale-set-listener













# win-arc-servicemonitors.yaml
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: arc-controller-metrics-win
  labels:
    release: kube-prometheus-stack
spec:
  namespaceSelector:
    matchNames: [win-runner-controller]
  selector:
    matchLabels:
      app: arc-controller
  endpoints:
    - port: http-metrics
      path: /metrics
      interval: 30s
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: arc-listener-metrics-win
  labels:
    release: kube-prometheus-stack
spec:
  namespaceSelector:
    matchNames: [win-runner-controller]
  selector:
    matchLabels:
      app: arc-listener
  endpoints:
    - port: http-metrics
      path: /metrics
      interval: 30s




kubectl -n monitoring delete pvc -l app.kubernetes.io/name=grafana --ignore-not-found
kubectl -n monitoring delete pvc -l app.kubernetes.io/name=prometheus --ignore-not-found
kubectl -n monitoring delete pvc -l app.kubernetes.io/name=alertmanager --ignore-not-found







kubectl get sc
# if you do NOT see one marked (default), create it:
cat <<'EOF' | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp3
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: ebs.csi.aws.com
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
parameters:
  type: gp3
  encrypted: "true"
EOF





NS=monitoring
kubectl -n $NS patch prometheus   kube-prometheus-stack-prometheus   --type=merge -p '{"spec":{"replicas":0}}'
kubectl -n $NS patch alertmanager kube-prometheus-stack-alertmanager --type=merge -p '{"spec":{"replicas":0}}'
kubectl -n $NS scale deploy kube-prometheus-stack-grafana --replicas=0 || true

# wait until no Prom/AM/Grafana pods remain
kubectl -n $NS get pods -w




# list PVCs so we use exact names
kubectl -n $NS get pvc

# example names (adjust to your output):
PROM_PVC=prometheus-kube-prometheus-stack-prometheus-db-prometheus-kube-prometheus-stack-prometheus-0
AM_PVC=alertmanager-kube-prometheus-stack-alertmanager-db-alertmanager-kube-prometheus-stack-alertmanager-0
GRAFANA_PVC=kube-prometheus-stack-grafana

# remove pvc-protection finalizer just in case it blocks deletion
kubectl -n $NS patch pvc $PROM_PVC   --type=merge -p '{"metadata":{"finalizers":[]}}' || true
kubectl -n $NS patch pvc $AM_PVC     --type=merge -p '{"metadata":{"finalizers":[]}}' || true
kubectl -n $NS patch pvc $GRAFANA_PVC --type=merge -p '{"metadata":{"finalizers":[]}}' || true

# delete the PVCs
kubectl -n $NS delete pvc $PROM_PVC --ignore-not-found
kubectl -n $NS delete pvc $AM_PVC   --ignore-not-found
kubectl -n $NS delete pvc $GRAFANA_PVC --ignore-not-found


NS=monitoring

# 1) Make sure the workloads are RUNNING (replicas=1). This creates the “consumer”.
kubectl -n $NS patch prometheus   kube-prometheus-stack-prometheus   --type=merge -p '{"spec":{"replicas":1}}'
kubectl -n $NS patch alertmanager kube-prometheus-stack-alertmanager --type=merge -p '{"spec":{"replicas":1}}'
kubectl -n $NS scale deploy kube-prometheus-stack-grafana --replicas=1

# 2) Watch PVCs bind (the VOLUME column will get a PV name)
kubectl -n $NS get pvc -w



# make sure workloads are not scaled to 0 from earlier steps
kubectl -n monitoring patch prometheus   kube-prometheus-stack-prometheus   --type=merge -p '{"spec":{"replicas":1}}' || true
kubectl -n monitoring patch alertmanager kube-prometheus-stack-alertmanager --type=merge -p '{"spec":{"replicas":1}}' || true
kubectl -n monitoring scale deploy kube-prometheus-stack-grafana --replicas=1 || true




helm -n monitoring status kube-prometheus-stack
helm -n monitoring history kube-prometheus-stack

# pick the last number in the "STATUS  deployed" row
REV=$(helm -n monitoring history kube-prometheus-stack | awk '/deployed/{rev=$1} END{print rev}')
helm -n monitoring rollback kube-prometheus-stack ${REV}


helm -n monitoring uninstall kube-prometheus-stack
# if Terraform still thinks it exists, drop it from state once:
terraform state rm module.prometheus_stack.helm_release.prometheus_stack




NS=monitoring
REL=kube-prometheus-stack

# 1) find the last *deployed* revision
REV=$(helm -n "$NS" history "$REL" | awk '/deployed/{rev=$1} END{print rev}')

# 2) rollback to that good revision (this clears the pending state)
helm -n "$NS" rollback "$REL" "$REV"

# (optional) confirm it's healthy
helm -n "$NS" status "$REL"
kubectl -n "$NS" get pods,pvc,ing -o wide




# username
kubectl -n monitoring get secret kube-prometheus-stack-grafana \
  -o jsonpath='{.data.admin-user}' | base64 -d; echo

# password
kubectl -n monitoring get secret kube-prometheus-stack-grafana \
  -o jsonpath='{.data.admin-password}' | base64 -d; echo



